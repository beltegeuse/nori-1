<div style="margin-top:-20px">
<h3>Part 1: Average Visibility Integrator <em>(xx points)</em></h3>
<div class="text-justify">
<p>
	In this exercise you will implement a new integrator <tt>nori::AV</tt> which derives from <tt>nori::Integrator</tt>. This integrator will be used to visualize the average visibility at the first camera intersection with geometry while ignoring the actual material parameters (<tt>BSDF</tt>). 
</p>

	<h4>Uniform Sphere Sampling <em>(xx points)</em></h4>
	<p>
		Implement a new method which takes a <tt>nori::Sampler *</tt> as a parameter and will return a uniformly distributed random <tt>Point3f</tt> on the surface of a unit sphere (i.e. radius of 1). A naive method to generate such a point is by using rejection sampling and then projection. First you can generate a uniform point within a unit cube (from [-1,-1,-1] to [1,1,1]). Points generated outside the unit sphere are rejected whereas points inside the unit sphere are accepted.
	</p>

	<h4>Uniform Hemisphere Sampling <em>(xx points)</em></h4>
	<p>
		Implement a new method which takes a nori::Sampler * and a Normal and returns a uniformly distributed random Point3f on the surface of a unit hemisphere (radius of 1) with its north pole collocated with the Normal given as parameter.
	</p>

	<h4>Implement Average Visibility Integrator <em>(xx points)</em></h4>
	<p>
		This function will be called multiple times for each camera ray and will be internally averaged by nori. First find if the camera ray given as a parameter intersects an object using <tt>scene->rayIntersect(const Ray3f ray,Intersection & its)</tt>. If nothing is intersected return black. In the case where an intersection was found you must now compute the average visibility. Using the intersection point <tt>its.p</tt> and the world space shading normal <tt>its.shFrame.n</tt>  and sampler you can generate a uniformly distributed ray on the defined hemisphere. This function should return 0 if the new ray is occluded and 1 otherwise.
	</p>

	<h4>Validation <em>(xx points)</em></h4>
	<p>
		Some test to implement...
	</p>

<h3>Part 2: Direct Illumination Integrator <em>(xx points)</em></h3>

	<h4>Point Lights <em>(xx points)</em></h4>
	Before starting, read section 12.2 in the textbook about point lights. Implement a <tt>nori::PointLight</tt> class which derives from <tt>nori::Emitter</tt> and implements an infinitesimal light source which emits light uniformly in all directions. Point lights should be instantiated by the parser during the loading of the scene and will be used by your various integrators during render time. Parametrize your point light with a <tt>Color3f</tt> power (Watts) and the world space position of the point light. Implement a new method in <tt>PointLight</tt> class which returns incident radiance at an intersection (given as a parameter) from this point light. 

	<h4>Direct Illumination integrator <em>(xx points)</em></h4>
	<tt>nori::Direct::Li</tt> will be called multiple times for each camera ray and will be internally averaged by nori. Its expected to return a one sample estimate of the incident radiance along the camera <tt>Ray3f</tt> which is given as a parameter. The equation which will be solved (15.1) is defined in the textbook in chapter 15 page 744. For the purposes of this exercise you can safely assume that there will be no emission at the first intersection. At the first camera ray intersection compute incident radiance from all your point lights in the scene, multiply that by the BSDF and a cosine term. 

	<h4>Validation <em>(xx points)</em></h4>
	<p>
		Some test to implement...
	</p>


<h3>Part 3: Interesting Scene <em>(xx points)</em></h3>
	<p>
	Include in your report an interesting scene which was rendered using one of your newly implemented integrators for this assignment.
	</p>


<h3> Hacker Points <em>(xx points)</em></h3>

	<div class="alert alert-danger" role="alert"><b>Disclaimer</b>: Hacker points are “underpriced” bonus points for the daring few. Sometimes you might be required to implement something that was not taught in class and will you will have to do some research and creative thinking. Hacker Points are awarded only to students who implemented 100% of the remaining normal assignment points.
	</div>

	<p> 
	The goal of this exercise is to improve the performance of the current acceleration structure (<tt>nori::BVH</tt>) during render time. You are given a scene (<tt>./scenes/sponza.xml</tt>) which should use xx.xx ray-triangle intersections per ray camera ray for the <tt>nori::AV</tt> integrator. Your goal is to reduce that number without  changing the rendered result and detail in your report your changes and their individual impact during render time and construction time.
	</p>

</div>
</div>
