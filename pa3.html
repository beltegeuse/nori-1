<div style="margin-top:-20px; text-align:justify">

	\(
	   \def\bold#1{\boldsymbol{#1}}
	   \def\vp{p}
	   \def\vr{r}
	   \def\integrand{\mathcal{F}}
	   \definecolor{red}{RGB}{203,23,206}
	\)

	<h3>Preliminaries</h3>


	<p>
		Begin by importing the base code updates into your repository by
		running <tt>git pull</tt>, cmake and recompiling. If there were any concurrent
		changes to the same file, you may have to perform a <em>merge</em> (see
		the git tutorials under "Preliminaries" for more information).
	</p>

	<p>
		In this exercise you will use your point sets in the context of
		rendering. You will be implementing various flavors of direct
		illumination integrators with different sampling distributions. You
		also will add new kinds of emitters with finite extent and a new
		microfacet BRDF. Your new integrators will compute the <em>local
		illumination integral</em> discussed in class:
	</p>
	\[
		L_o (\vp,\omega_o) = L_e(\vp,\omega_o) + \int_{H^2} f_r (\vp,\omega_o,\omega_i)\,L_i (\vp,\omega_i) \, \mathrm{d} \omega_i.
	\]
	where \(f_r\) is the BRDF, \(p\) is a surface position and \(L_i\) and \(L_o\) denote the incident and outgoing radiance functions.
	Generally, \(L_i\) and \(L_o\) are related to each other using the ray tracing operator
	\(\vr(p, \omega)\), which returns the nearest surface position visible along the ray \(\vp, \omega\), i.e.
	\[
		L_i(\vp,\omega)=L_o(\vr(\vp, \omega), -\omega)
	\]
	and the above integral is thus defined recursively. In this assignment, we focus on <em>direct illumination</em>
	only and therefore truncate the recursion after the first light bounce. This means that the integral is now given by
	\[
	L_o (\vp,\omega_o) = L_e(\vp,\omega_o) + \int_{H^2} \underbrace{f_r (\vp,\omega_o,\omega_i)\,L_e (\vr(\vp,\omega_i), -\omega_i)}_{=: \integrand(\vp, \omega_o, \omega_i)} \, \mathrm{d} \omega_i.
	\]
	<p>
		We set \(\integrand(\vp, \omega_o, \omega_i)\) as the integrand in the above expression to simplify the notation below.
	</p>

	<p>
		In comparison to the last assignment, we will be be working with emitters that have a finite extent, which means that
		they can be directly observed by the camera. This is why the first summand in the above equation is needed: it
		returns emitted radiance towards the camera when light sources are visible on screen.
		Also note that the above equation defines outgoing radiance at surface points. To visualize incident
		radiance at the camera, you will need one more invocation of the ray tracing operator.
	</p>
	<p>
		Like in the first assignment, we don't explicitly specify an API that
		you should use to implement the sampling and evaluation operations for
		emittersâ€”finding suitable abstractions is part of the exercise.
		That said, you can look at the <code>BSDF</code> definitions in
		<tt>include/nori/bsdf.h</tt> to get a rough idea as to
		how one might get started with such an interface.
	</p>

	<div class="row" style="margin: 30px">
		<div class="col-md-3">
			<div class="thumbnail" style="margin: 10px">
				<a class="fancybox" href="images/sphere_ao_ems_256spp.png"><img src="images/sphere_ao_ems_256spp.png"/></a>
				<div class="caption">
					A diffuse sphere illuminated by a distant disk light that subtends an angle of 180 degrees.
				</div>
			</div>
		</div>
		<div class="col-md-3">
			<div class="thumbnail" style="margin: 10px">
				<a class="fancybox" href="images/sphere_side_mis_128spp.png"><img src="images/sphere_side_mis_128spp.png"/></a>
				<div class="caption">
					A diffuse sphere illuminated by a distant disk light that subtends an angle of 10 degrees.
				</div>
			</div>
		</div>
		<div class="col-md-3">
			<div class="thumbnail" style="margin: 10px">
				<a class="fancybox" href="images/odyssey_mis_64spp.png"><img src="images/odyssey_mis_64spp.png"/></a>
				<div class="caption">
					A rendering of the <tt>odyssey</tt> scene using multiple importance sampling and 64 samples per pixel.
				</div>
			</div>
		</div>

		<div class="col-md-3">
			<div class="thumbnail" style="margin: 10px">
				<a class="fancybox" href="images/veach_mis_128spp.png"><img src="images/veach_mis_128spp.png"/></a>
				<div class="caption">
					A rendering of the <tt>veach</tt> scene using multiple importance sampling and 128 samples per pixel.
				</div>
			</div>
		</div>
	</div>

	<h3>Part 1: Light Sampling <em>(55 points)</em></h3>
	<ul>
		<li>
		<h4>Integrator Implementation <em>(10 Points)</em></h4>

		<p>
			In this part you will implement a new direct illumination integrator (<tt>direct_ems</tt>)
			which can integrate incident radiance by performing emitter sampling. In addition to point lights this integrator will
			be able to handle two additional types of emitters: distant disk lights and mesh (area) lights. These new emitters
			can be fully, partially or not at all visible from a point in your scene, so you will perform MC integration to compute
			reflected radiance (accounting also for visibility) at your first camera intersection.
			For this part of the assignment you will distribute your samples for the new emitters according to an emitter
			specific density function \(\text{pdf}_\text{em}\):
			\[
			L_o (p,\omega_o) \approx \frac{1}{N} \sum_{k=1}^N \left( L_e(p,\omega_o) + \frac{\integrand\left(p,\omega_o,\omega_i^{(k)}\right)}{\text{pdf}_{\text{em}}\left(\omega_i^{(k)}\right)} \right)\\
			\]
		</p>
		</li>

		<li>
			<h4>Distant Disk Light <em> (10 Points)</em></h4>
			<p>
				There can be at most one distant disk emitter per scene; when present, it is fully specified
				by its radiance, a <tt>toWorld</tt> transformation and the angle subtended
				by the light source as seen by object in the scene when there is no occlusion
				\(\theta_a \in [0^\circ,180^\circ]\). For a values of \(\theta_a \to 0\) the emitter tends
				to a directional light source and for a value of \(\theta_a = 180\) the emitter is a constant
				spherical environment map. In addition the emitter can be rotated using a
				<tt>toWorld</tt> transformation. You can safely assume 
				that only rotations are allowed as transformations for this emitter.
				When no transformation
				is given (i.e <tt>toWorld</tt> \(= \bold{I} \)) then the subtended angle
				is measured (in degrees) from the Z-axis \([0,0,1]\). Here is how instances
				of <tt>distantdisk</tt> will be specified in Nori's scene description language:
			</p>
			<pre class="prettyprint linenums lang-xml">
&lt;scene&gt;
    &lt;!-- Define a distant disk emitter --&gt;
    &lt;emitter type="distantdisk"&gt;
        &lt;!-- Set the radiance to a 60 W/m<sup>2</sup>sr  for all channels --&gt;
        &lt;color name="radiance" value="60"/&gt;

        &lt;!-- Set the subtended angle to 5 degrees --&gt;
        &lt;float name="thetaA" value="5"/&gt;

        &lt;!-- Rotate the disk 30 degrees counter-clockwise around the Y-axis --&gt;
        &lt;transform name="toWorld"/&gt;
            &lt;rotate axis="0,1,0" value="30"/&gt;
        &lt;/transform&gt;

    &lt;/emitter&gt;

    &lt;!-- ..... --&gt;
&lt;/scene&gt;
			</pre>

				<ul>
					<li>
					<h4> Radiance Evaluation Method <em>(5 points)</em> </h4>
					<p>
					In your <tt>DistantDisk</tt> class, implement a method which will be called whenever a ray escapes your scene or when doing shadow connections. After transforming \(\bold{\omega_e}\) in the emitters local coordinate system, this method will return the constant radiance value when the angle from Z-axis is less or equal than \(\theta_a\) and zero otherwise. Remember to convert your angles to radians before
					using the standard trigonometric functions. Here is a usage example for the world-to-local and local-to-world transformations:
					</p>

					<div class="row">
						<div class="col-md-6">
							<pre class="prettyprint linenums " >
// Constructor example

/* Read a toWorld transform from the XML scene
   specification. If not present, use the identity */
m_emitterToWorld = propList.getTransform(
		"toWorld", Transform());

/* Invert the toWorld transformation */
m_worldToEmitter = m_emitterToWorld.inverse();

//...
							</pre>
						</div>

						<div class="col-md-6">
							<pre class="prettyprint linenums ">
// Usage Example

/* Convert a world space direction to
   a local direction and vice versa    */

Vector3f d1_local = m_worldToEmitter * d1_world;
Vector3f d2_world = m_emitterToWorld * d2_local;

//...


							</pre>
						</div>
					</div>
					</li>

					<li>
						<h4> Sampling and Density Methods <em>(5 points)</em> </h4>
						<p>
						Implement a method for generating a world space direction uniformly over the subtended solid angle of the distant disk light. You might find <code>Warp::squareToUniformSphericalCap</code> and your <tt>toWorld</tt> transformations useful. Implement another method which returns the probability density of the sampling method for a given a world space direction.
						</p>
					</li>
				</ul>
		</li>

		<li>
			<h4>Mesh Area Light<em> (25 Points)</em></h4>
			<p>
				The mesh area light source is an area light source that can be attached to meshes. It emits radiance uniformly in all directions from each triangle of the mesh.
				It is parametrized by radiance. Here is how instances of <tt>area</tt> emitters will be specified in Nori's scene description language:
			</p>
			<pre class="prettyprint linenums lang-xml">
&lt;scene&gt;
    &lt;!-- Load a Wavefront OBJ file named "mesh.obj" --&gt;
    &lt;mesh type="obj"&gt;
        &lt;string name="filename" value="mesh.obj"/&gt;

        &lt;!-- Turn the mesh into an area light source --&gt;
        &lt;emitter type="area"&gt;
            &lt;!-- Assign a uniform radiance of 1 W/m<sup>2</sup>sr --&gt;
            &lt;color name="radiance" value="1,1,1"/&gt;
        &lt;/emitter&gt;
    &lt;/mesh&gt;

    &lt;!-- ..... --&gt;
&lt;/scene&gt;
			</pre>

				<ul>
					<li>
					<h4> Radiance Evaluation Method <em>(5 points)</em> </h4>
						In your <code>AreaEmitter</code> class implement a method
						which can be called by the integrators whenever a ray
						intersects your mesh emitter. Given a camera
						ray intersection point \(p_c\) with an emitter this function should
						return the associated radiance value when the front
						side of an emissive triangle was intersected and zero otherwise.
						This method (or a separate one) should also be able to return the radiance of points on the
						emitter that are not directly seen by the camera (ignoring occlusion for now),
						which will be needed for direct illumination sampling.
					</li>

					<li>
						<h4> <tt>Mesh</tt> Sampling and Density Methods <em>(15 points)</em> </h4>
						<p>
						Familiarize yourself with the <code>Mesh</code> class to see how vertices, faces and normals are stored. In this class, implement a method that uniformly samples positions on the surface and also computes the corresponding normal. Additionally implement a method that returns the density function of your importance sampling technique.
						</p>
						<p> You can perform your sampling by first choosing a triangle from the mesh according to its area, and then sampling uniformly within that triangle. Interpolate the vertex normals when they are provided or compute the normal to the plane defined by the corresponding triangle otherwise. You may find the <code>DiscretePDF</code> class useful. For efficiency, build a discrete PDF over triangles once when the <code>activate()</code> method of the <code>Mesh</code> is called, and use this precomputed data in your sampling code.
						</p>
					</li>

					<li>
						<h4> <tt>AreaEmitter</tt> Sampling and Density Methods <em>(5 points)</em> </h4>
						With the help of your sampling and density methods implemented in the <tt>Mesh</tt> class, implement the corresponding sampling methods in your area emitter.
						Your density evaluation method takes as input a world space direction (along with the corresponding sampled position and normal on your emitter) generated using your sampling method returns the probability density used when converted to solid angle measure. Make sure to return zero whenever a back facing triangle is encountered.
					</li>
				</ul>
		</li>

		<li>
			<h4>Validation <em> (10 Points)</em></h4>
			<p>
				Pass the the <tt>direct_ems</tt> related tests found in <tt>./scenes/pa3/tests</tt>: 
				<ul> 
					<li> first 4 t-tests in <tt>test-distant.xml</tt>, </li>
					<li> first 5 tests in <tt>test-mesh.xml</tt>, </li>
					<li> first 2 tests in <tt>test-mesh-furnace.xml</tt> </li>
				</ul>
			</p>
			<p>
				Using <tt>direct_ems</tt> render the following scenes found in <tt>./scenes/pa3</tt> : 
				<ul>
					<li><tt>sphere/sphere_ao_ems.xml</tt>, </li>
					<li><tt>sphere/sphere_side_ems.xml</tt>, </li>
				</ul>
			</p>
		</li>


	</ul>


	<h3>Part 2: BRDF Sampling <em>(40 points)</em></h3>
	<ul>
		<li>
		<h4>Integrator Implementation <em>(10 Points)</em></h4>

		<p>
			In this part we will implement a new direct illumination integrator (<tt>direct_mats</tt>)
			that can integrate incident radiance from mesh lights and distant disk lights. In addition
			you will implement a new microfacet BRDF. For this part of the assignment you will distribute
			your samples according to a BRDF specific density function :
			\[
			L_o (p,\omega_o) \approx \frac{1}{N} \sum_{k=1}^N \left( L_e(p,\omega_o) + \frac{\integrand(p,\omega_o,\omega_i^{(k)})}{\text{pdf}_{\text{mat}}\big(\omega_i^{(k)}\big)} \right)
			\]
			This integrator should produce black images with zero-valued pixels
			when given a scene containing only point lights, since the probability
			of intersecting them with this sampling strategy is zero.
		</p>
		</li>

		<li>
			<h4>Microfacet BRDF Evaluation <em> (5 Points)</em></h4>
			<p>
				The Microfacet BRDF you will implement for this part is a simple linear blend between a diffuse BRDF and a rough dielectric microfacet BRDF. Implement <code>Microfacet::eval()</code> which evaluates the described microfacet BRDF for a given pair of directions in local frame:
				\[
					f_r(\bold{\omega_i},\bold{\omega_o}) = \frac{k_d}{\pi} + {\color{red} k_s} \frac{D(\bold{\omega_{h}})~
					F\left({\color{red}(\bold{\omega_h} \cdot \bold{\omega_i})}, \eta_{e},\eta_{i}\right)~
					G(\bold{\omega_i},\bold{\omega_o},\bold{\omega_{h}})}{4 \cos{\theta_i} \cos{\theta_o}}, ~~
					\bold{\omega_{h}} = \frac{\left(\bold{\omega_i} + \bold{\omega_o}\right)}{\left|\left|\bold{\omega_i} + \bold{\omega_o}\right|\right|_2}
				\]
				where \(k_d \in [0,1]^3\) is the RGB diffuse reflection coefficient, \(\color{red} k_s = 1 - \max(k_d)\), \(F\) is the fresnel reflection coefficient (check <tt>common.cpp</tt>), \(\eta_e\) is the exterior index of refraction and \(\eta_i\) is the interior index of refraction. The distribution function \(D\) is the Beckmann distribution:

				\[
					D(\bold{\omega_{h}}) = \frac{e^{\frac{-\tan^2{\theta_{h}}}{\alpha^2}}}{\pi\, \alpha^2 \cos^4 \theta_{h} }

				\]

				with its corresponding shadowing term approximation (Smith):

				\[
					G(\bold{\omega_i},\bold{\omega_o},\bold{\omega_{h}}) = G_1(\bold{\omega_i},\bold{\omega_{h}})~G_1(\bold{\omega_o},\bold{\omega_{h}})
				\]

				\[
					G_1(\bold{\color{red}\omega_v},\bold{\omega_h}) = \chi^+\left(\frac{\color{red}\bold{\omega_v}\cdot\bold{\omega_h}}{\color{red}\bold{\omega_v}\cdot\bold{n}}\right)
					\begin{cases}
						\frac{3.535b+2.181b^2}{1+2.276b+2.577b^2} & b \lt 1.6 \\
						1 										  & \text{otherwise}
					\end{cases} \\

					b = (a \tan{\color{red}\theta_v})^{-1}, ~~

					\chi^+(c) =
					\begin{cases}
						1 & c > 0 \\
						0 & c \le 0
					\end{cases} \\

				\]
				where \(\color{red}\theta_v\) is the angle between the surface normal \(\bold{n}\)
				and the \(\color{red}\omega_v\) argument of \(G_1\).

				</p>
		</li>
		<li>
			<h4>Microfacet BRDF Sampling <em> (15 Points)</em></h4>
			<p>
				In this part you will generate samples according to the following density function:
				\[
					k_s ~ D(\omega_h) \cos{\theta_h} ~ J_h + (1-k_s) \frac{\cos{\theta_o}}{\pi}
				\]
				where \(J_h = (4 (\omega_h \cdot \omega_o))^{-1}\) 
				is the Jacobian of the half direction mapping discussed in class.
				Choose whether to sample the diffuse or the specular component
				based on the value of \(k_s\). In the first case, follow the
				recipe from the slides, by sampling a normal from the microfacet
				distribution and reflecting the incident direction using this normal.
				In the latter case, generate a cosine-weighted direction on the sphere
				using the same method as the model in <tt>src/diffuse.cpp</tt>.
			</p>
		</li>
		<li>
			<h4>Validation <em> (10 Points)</em></h4>
			<p>
				You can experiment with the warptest GUI and visualize your
				implemented BRDF. Pass all the \(\chi^2\) and t-tests for the
				Microfacet BRDF found in <tt>./scenes/pa3/tests</tt>: 
				<ul> 
					<li><tt>chi2test-microfacet.xml</tt>, </li>
					<li><tt>ttest-microfacet.xml</tt></li>
				</ul>
				Note that the visual GUI also contains
				a \(\chi^2\) test, but this is just to facilitate debugging and
				visualization; the XML files are the real validation benchmark.
			</p>
			<p>
				Pass the <tt>direct_mats</tt> related t-tests found in <tt>./scenes/pa3/tests</tt>: 
				<ul>
					<li><tt>test-distant.xml</tt> (second set of 4 tests), </li>
					<li><tt>test-mesh.xml</tt> (second set of 5 tests), </li>
					<li><tt>test-mesh-furnace.xml</tt> (second set of 2 tests) </li>
				</ul>
				Mention in your report if there any errors reported.
			</p>

			<p>
				Using <tt>direct_mats</tt> render the following scenes found in <tt>./scenes/pa3</tt> : 
				<ul>
					<li><tt>sphere/sphere_ao_mats.xml</tt>, </li>
					<li><tt>sphere/sphere_side_mats.xml</tt>, </li>
					<li><tt>odyssey/odyssey_mats.xml</tt>, </li>
					<li><tt>veach_mi/veach_mats.xml</tt></li>
				</ul>
			</p>

		</li>


	</ul>


	<h3>Part 3: Multiple Importance Sampling <em>(20 Points)</em></h3>
	<ul>
		<li>
			<h4>Integrator Implementation <em>(10 Points)</em></h4>
			<p>
				In this part we will implement another direct illumination integrator (<tt>direct_mis</tt>)
				This integrator will combine both sampling strategies for computing direct illumination by using multiple importance sampling with the balance heuristic.
				At your first camera ray intersection you will sample using both strategies: sampling the emitters and sampling the corresponding BSDF. You will then combine the
				two estimates by using the following expression:
			</p>

			\[
				  L_o (p,\omega_o) \approx \frac{1}{N} \sum^N \left(
						L_e(p,\omega_o) + w_\text{em}\frac{\integrand(p,\omega_o,\omega_{i,e}) }{\text{pdf}_\text{em}(\omega_{i,e})}

					+ w_\text{mat} \frac{\integrand(p,\omega_o,\omega_{i,m}) }{\text{pdf}_\text{mat}(\omega_{i,m})}
					\right)\\
					w_\text{em} = \frac{\text{pdf}_\text{em}(\omega_{i,e}) }{\text{pdf}_{\text{em}}(\omega_{i,e})+\text{pdf}_{\text{mat}}(\omega_{i,e})}, ~ ~
					w_\text{mat} = \frac{\text{pdf}_\text{mat}(\omega_{i,m}) }{\text{pdf}_{\text{em}}(\omega_{i,m})+\text{pdf}_{\text{mat}}(\omega_{i,m})}
			\]
			<p>
			For this to work, it is <em>crucial</em> that the probability
			densities are expressed in terms of the same units (so either
			density per unit solid angle, or density per unit area). Mixing
			units will lead to suboptimal weights.
			</p>

		<li>
			<h4>Validation <em> (10 Points)</em></h4>
			<p>
				Pass the <tt>direct_mis</tt> related t-tests found in <tt>./scenes/pa3/tests</tt>: 
				<ul>
					<li>last 4 tests in <tt>test-distant.xml</tt>,</li>
					<li>last 5 tests in <tt>test-mesh.xml</tt>,</li>
					<li>last 2 tests in <tt>test-mesh-furnace.xml</tt> </li>
				</ul>
				Mention in your report if there any errors reported.
			</p>
			<p>
				Using <tt>direct_mis</tt> render the following scenes found in <tt>./scenes/pa3</tt> : 
				<ul>
					<li><tt>sphere/sphere_ao_mis.xml</tt>, </li>
					<li><tt>sphere/sphere_side_mis.xml</tt>, </li>
					<li><tt>odyssey/odyssey_mis.xml</tt>, </li>
					<li><tt>veach_mi/veach_mis.xml</tt> </li>
				</ul>
			</p>			
			<p>
				Show a 4-way comparison for each of the 4 scenes in your report. For each scene compare
				your 3 integrators (<tt>direct_ems</tt>, <tt>direct_mats</tt>, <tt>direct_mis</tt>) with the 
				reference MIS rendering.
			</p>
		</li>


	</ul>


	<h3>Part 4: Interesting Scene <em>(10 Points)</em></h3>

	Make your own interesting scene and submit a rendering (or several) using any combination of the implemented techniques. The filename format for this scene should be <tt>interesting-pa3-firstname-familyname-N}</tt>, where N depends on how many interesting images you are submitting. Be creative, your renderings will be posted on the Course Gallery.

	<h3> Hacker Points: Specialized Light Source Sampling <em>(15 points)</em></h3>

	<p>
		For this part your task is to create three efficient specialized emitters (rectangle,
		sphere and disk lights) that can improve the sample variance of your
		integrators with respect to your current generalized mesh emitter implementation.
		Identify the sources of variance in your existing implementation, address them 
		and validate your results. Possible sources of variance are:
		<ul>
			<li> Zero contribution (wasted) samples (e.g. not visible samples on a sphere light). </li>
			<li> High variance samples (e.g. distance squared in density function). </li>
			<li> Bad distribution of samples (e.g. clumping of samples because of independent sampling). </li>
		</ul>
	</p>

	<p>
		Your goal is to optimize sampling for these specialized light sources by improving all three sources of variance
		mentioned above.
	</p>


	<h4> What to submit </h4>
	<p>
		<ul>
			<li> Implementation of your specialized classes for each if the three emitters which passes your t-tests.</li>
			<li> A paragraph in your report (per emitter) explaining the optimizations you implemented and how they relate to the aforementioned sources of variance.</li>
			<li> Your t-test xml files (for each emitter: a file with 3 or more tests each).</li>
			<li> A table and a paragraph in your report summarizing the variance improvement for your test cases.</li>
			<li> An equal sample count comparison with your previous generalized implementation of a scene featuring all emitters.</li>
			<li> Citations for any papers/ideas that you relied on.</li>
		</ul>
	</p>

</div>
